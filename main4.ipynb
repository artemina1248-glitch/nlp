{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9585dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemuna/d1/nlpm/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/pkugoodspeed/nlpword2vecembeddingspretrained?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.46G/2.46G [00:58<00:00, 45.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/artemuna/.cache/kagglehub/datasets/pkugoodspeed/nlpword2vecembeddingspretrained/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"pkugoodspeed/nlpword2vecembeddingspretrained\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6392e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleNews-vectors-negative300.bin\n",
      "glove.6B.300d.txt\n",
      "glove.6B.200d.txt\n",
      "glove.6B.50d.txt\n",
      "glove.6B.100d.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/home/artemuna/.cache/kagglehub/datasets/pkugoodspeed/nlpword2vecembeddingspretrained/versions/1\"\n",
    "\n",
    "# 列出文件\n",
    "for file in os.listdir(folder_path):\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d2cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_848/2081348066.py:11: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 原始 GloVe 文件路径\n",
    "glove_input_file = \"/home/artemuna/.cache/kagglehub/datasets/pkugoodspeed/nlpword2vecembeddingspretrained/versions/1/glove.6B.300d.txt\"\n",
    "\n",
    "# 转换后的中间 word2vec 文件\n",
    "word2vec_output_file = \"/tmp/glove.6B.300d.word2vec.txt\"\n",
    "\n",
    "# 1️⃣ 先转换格式\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "# 2️⃣ 再加载为 gensim 的 KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a46de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/artemuna/.cache/kagglehub/datasets/pkugoodspeed/nlpword2vecembeddingspretrained/versions/1/glove.6B.300d.txt\"\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    for _ in range(10):\n",
    "        print(f.readline().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9800075f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20842  , -0.019668 ,  0.063981 , -0.71403  , -0.21181  ,\n",
       "       -0.59283  , -0.15316  ,  0.044217 ,  0.63289  , -0.84821  ,\n",
       "       -0.21129  , -0.19763  ,  0.19029  , -0.56226  ,  0.27126  ,\n",
       "        0.23782  , -0.5189   , -0.24518  ,  0.035243 ,  0.096833 ,\n",
       "        0.24898  ,  0.71279  ,  0.038279 , -0.10514  , -0.4779   ,\n",
       "       -0.39515  , -0.27194  , -0.44428  ,  0.06113  , -0.2318   ,\n",
       "       -0.35901  , -0.18239  ,  0.035507 , -0.087719 , -1.0816   ,\n",
       "       -0.42521  ,  0.003224 , -0.45991  , -0.043462 , -0.39031  ,\n",
       "        0.519    ,  0.21139  , -0.25527  ,  1.1805   , -0.19041  ,\n",
       "       -0.12156  ,  0.034186 , -0.062316 ,  0.14421  , -0.53366  ,\n",
       "        0.47425  , -0.4471   ,  0.58047  ,  0.43578  ,  0.1321   ,\n",
       "       -0.095712 , -0.37182  , -0.013837 ,  0.20601  , -0.10099  ,\n",
       "        0.10685  , -0.33723  ,  0.10986  ,  0.34796  , -0.099839 ,\n",
       "        0.36942  , -0.52917  ,  0.12407  , -0.46127  , -0.38483  ,\n",
       "       -0.10114  , -0.17634  ,  0.37574  ,  0.16377  , -0.2198   ,\n",
       "       -0.26841  ,  0.84706  , -0.35619  , -0.083992 , -0.20276  ,\n",
       "       -0.56542  ,  0.19112  , -0.14134  , -0.7812   ,  0.69188  ,\n",
       "       -0.083628 , -0.54293  ,  0.16437  ,  0.037606 , -0.68896  ,\n",
       "       -0.68711  , -0.13367  , -0.4779   ,  0.20125  ,  0.085122 ,\n",
       "       -0.063865 , -0.17104  , -0.32432  , -0.17623  , -0.514    ,\n",
       "       -0.50289  ,  0.23204  , -0.11324  , -1.064    , -0.035359 ,\n",
       "       -0.5068   , -0.27118  , -0.16621  , -0.63016  ,  0.054252 ,\n",
       "       -0.048178 ,  0.29282  , -0.030666 , -0.24645  , -0.27084  ,\n",
       "       -0.42563  , -0.39171  ,  0.18428  , -0.017772 , -0.35334  ,\n",
       "       -0.49075  , -0.90782  ,  0.13872  , -0.76521  , -0.46318  ,\n",
       "       -0.32124  , -0.086228 ,  1.0448   , -0.39919  ,  0.69478  ,\n",
       "       -0.10377  ,  0.86715  ,  0.22742  ,  0.4384   ,  0.085767 ,\n",
       "       -0.22846  ,  0.4309   ,  0.064187 , -0.027926 , -0.093056 ,\n",
       "        0.65188  ,  0.59143  , -0.3376   , -0.37732  ,  0.0052212,\n",
       "        1.1193   , -0.23845  , -0.16029  ,  0.42877  , -0.16228  ,\n",
       "       -0.12202  , -0.1061   ,  0.015761 ,  0.022745 , -0.17734  ,\n",
       "       -0.091711 , -0.29158  ,  0.19034  , -0.35168  ,  0.27563  ,\n",
       "       -0.20577  ,  0.11472  , -0.34126  , -0.0065915,  0.14896  ,\n",
       "       -0.026762 ,  0.0019373,  0.53279  , -0.76088  ,  0.063085 ,\n",
       "       -0.72089  , -0.04128  , -0.96164  ,  0.020769 ,  0.16123  ,\n",
       "       -0.34342  ,  0.69713  , -0.16018  , -0.11701  , -0.070239 ,\n",
       "       -0.30774  ,  0.39741  ,  0.39994  , -0.678    ,  0.57684  ,\n",
       "       -0.48099  ,  0.59317  , -0.42262  ,  0.28613  , -0.26203  ,\n",
       "        0.052727 ,  0.61659  , -0.36801  , -0.28429  , -0.40054  ,\n",
       "       -0.30055  , -0.27444  , -0.045729 , -0.56105  ,  0.24176  ,\n",
       "        0.86631  , -0.83715  ,  0.13562  ,  0.26196  , -0.43055  ,\n",
       "        0.34558  ,  0.059441 ,  0.61845  ,  0.11837  , -0.019168 ,\n",
       "        0.47697  , -0.32465  , -0.15463  , -0.23556  , -0.64263  ,\n",
       "       -0.092156 , -0.19622  ,  0.40666  ,  0.18009  ,  0.094309 ,\n",
       "        0.046917 ,  0.26369  , -0.50727  ,  0.37491  , -0.66773  ,\n",
       "        0.35095  , -0.033835 ,  0.30534  ,  0.23166  ,  0.023526 ,\n",
       "       -0.68365  ,  0.26078  , -0.22526  , -0.2656   ,  0.59967  ,\n",
       "        0.2598   ,  0.36248  ,  0.15564  , -0.45549  ,  0.11153  ,\n",
       "       -0.33287  ,  0.081364 , -0.36989  , -0.25543  , -1.1628   ,\n",
       "       -0.14622  , -0.032971 , -0.55619  ,  0.47717  , -0.29021  ,\n",
       "        0.42688  ,  1.2397   , -0.81391  ,  0.21084  , -0.25426  ,\n",
       "       -0.08684  , -0.078412 ,  0.26035  ,  0.3281   , -0.23777  ,\n",
       "        0.05138  , -0.030247 , -0.15669  ,  0.057147 ,  0.33902  ,\n",
       "        0.12795  , -0.21468  , -0.75208  ,  0.41422  ,  0.0062719,\n",
       "       -0.52904  ,  0.92193  , -0.42179  , -0.69638  ,  0.074115 ,\n",
       "        0.19071  , -1.2031   , -0.081333 , -0.4914   , -0.22159  ,\n",
       "       -0.29876  ,  0.30094  ,  0.018634 ,  0.18786  , -0.45429  ,\n",
       "       -0.29296  ,  0.3695   , -0.24218  , -0.11803  ,  0.071775 ,\n",
       "        0.44026  , -0.59978  ,  0.45354  ,  0.17854  , -0.17155  ,\n",
       "        0.018811 , -0.62354  , -0.014163 ,  0.16799  , -0.064392 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b846ce0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lovely', 0.8095278739929199),\n",
       " ('gorgeous', 0.767159104347229),\n",
       " ('wonderful', 0.6419878005981445),\n",
       " ('magnificent', 0.632170557975769),\n",
       " ('elegant', 0.6133942008018494),\n",
       " ('charming', 0.5836594700813293),\n",
       " ('pretty', 0.5694172978401184),\n",
       " ('beauty', 0.5587742328643799),\n",
       " ('beautifully', 0.5468562245368958),\n",
       " ('splendid', 0.5426493287086487)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"beautiful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7795298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8065858483314514),\n",
       " ('queen', 0.689616322517395),\n",
       " ('monarch', 0.5575491189956665),\n",
       " ('throne', 0.5565375089645386),\n",
       " ('princess', 0.5518684387207031),\n",
       " ('mother', 0.5142154693603516),\n",
       " ('daughter', 0.5133156776428223),\n",
       " ('kingdom', 0.5025345087051392),\n",
       " ('prince', 0.5017741322517395),\n",
       " ('elizabeth', 0.4908031225204468)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model[\"king\"] - model[\"man\"] + model[\"woman\"]\n",
    "model.most_similar(positive=[vector])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6cb66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "product_adjs = [\n",
    "    \"national\",\n",
    "    \"dangerous\",\n",
    "    \"long\",\n",
    "    \"hot\",\n",
    "    \"public\",\n",
    "    \"whole\",\n",
    "    \"simple\",\n",
    "    \"hard\",\n",
    "    \"small\",\n",
    "    \"poor\",\n",
    "    \"large\",\n",
    "    \"now\",\n",
    "    \"private\",\n",
    "    \"different\",\n",
    "    \"high\",\n",
    "    \"good\",\n",
    "    \"awesome\",\n",
    "    \"great\"\n",
    "]\n",
    "\n",
    "# Define second group as h1\n",
    "human_adjs = [\n",
    "    \"excellent\",\n",
    "    \"current\",\n",
    "    \"real\",\n",
    "    \"amazing\",\n",
    "    \"low\",\n",
    "    \"lost\",\n",
    "    \"full\",\n",
    "    \"fantastic\",\n",
    "    \"special\",\n",
    "    \"beautiful\",\n",
    "    \"nice\",\n",
    "    \"right\",\n",
    "    \"available\",\n",
    "    \"wonderful\",\n",
    "    \"legal\",\n",
    "    \"local\",\n",
    "    \"fine\",\n",
    "    \"easy\",\n",
    "    \"political\",\n",
    "    \"old\",\n",
    "    \"close\",\n",
    "    \"strong\",\n",
    "    \"professional\",\n",
    "    \"busy\",\n",
    "    \"helpful\",\n",
    "    \"friendly\",\n",
    "    \"ready\",\n",
    "    \"pleasant\",\n",
    "    \"happy\",\n",
    "    \"militant\",\n",
    "    \"willing\",\n",
    "    \"young\",\n",
    "    \"junior\",\n",
    "    \"senior\",\n",
    "    \"able\",\n",
    "    \"concerned\",\n",
    "    \"pleased\",\n",
    "    \"sure\",\n",
    "    \"interested\",\n",
    "    \"glad\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9949c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def avg_vector(words, model):\n",
    "    vecs = [model[word] for word in words if word in model]\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "human_vec = avg_vector(human_adjs, model)\n",
    "product_vec = avg_vector(product_adjs, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5edf0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def classify_adj_by_prototype(adj, model, human_vec, product_vec):\n",
    "    if adj not in model:\n",
    "        return None\n",
    "    v = model[adj]\n",
    "    sim_to_human = 1 - cosine(v, human_vec)\n",
    "    sim_to_product = 1 - cosine(v, product_vec)\n",
    "    return (\"person\" if sim_to_human > sim_to_product else \"product\", sim_to_human, sim_to_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc1d88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def classify_adj_by_prototype(adj, model, human_vec, product_vec):\n",
    "    if adj not in model:\n",
    "        return None\n",
    "    v = model[adj]\n",
    "    sim_to_human = 1 - cosine(v, human_vec)\n",
    "    sim_to_product = 1 - cosine(v, product_vec)\n",
    "    return (\"person\" if sim_to_human > sim_to_product else \"product\", sim_to_human, sim_to_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c026724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggressive ('product', np.float32(0.3962645), np.float32(0.3987099))\n",
      "plastic ('product', np.float32(0.22752416), np.float32(0.31885296))\n",
      "elegant ('person', np.float32(0.28935206), np.float32(0.25249743))\n",
      "compact ('product', np.float32(0.19993985), np.float32(0.26742613))\n",
      "warm ('person', np.float32(0.43100423), np.float32(0.40670824))\n",
      "sharp ('product', np.float32(0.3305828), np.float32(0.33514857))\n",
      "soft ('product', np.float32(0.37286717), np.float32(0.3960541))\n",
      "rigid ('product', np.float32(0.15141988), np.float32(0.22396594))\n"
     ]
    }
   ],
   "source": [
    "adjectives_to_test = [\"aggressive\", \"plastic\", \"elegant\", \"compact\", \"warm\", \"sharp\", \"soft\", \"rigid\"]\n",
    "\n",
    "for adj in adjectives_to_test:\n",
    "    print(adj, classify_adj_by_prototype(adj, model, human_vec, product_vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9b2250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for filtered_person_adjs.csv:\n",
      "  → classified as person: 289\n",
      "  → classified as product: 262\n",
      "  → ratio: {'person': 0.5245009074410163, 'product': 0.47549909255898365}\n",
      "\n",
      "Results for strong_product_adjs.csv:\n",
      "  → classified as person: 301\n",
      "  → classified as product: 565\n",
      "  → ratio: {'person': 0.34757505773672054, 'product': 0.6524249422632794}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Assumes the following variables are already defined:\n",
    "# model: pretrained word embedding model (e.g., GloVe)\n",
    "# human_vec: averaged vector for human adjectives\n",
    "# product_vec: averaged vector for product adjectives\n",
    "\n",
    "# Classify a given adjective based on cosine similarity to prototype vectors\n",
    "def classify_adj_by_prototype(adj, model, human_vec, product_vec):\n",
    "    if adj not in model:\n",
    "        return None\n",
    "    v = model[adj]\n",
    "    sim_to_human = 1 - cosine(v, human_vec)\n",
    "    sim_to_product = 1 - cosine(v, product_vec)\n",
    "    return \"person\" if sim_to_human > sim_to_product else \"product\"\n",
    "\n",
    "# Load the first column (adjective list) from a CSV file\n",
    "def load_adjectives_from_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df.iloc[:, 0].dropna().unique().tolist()\n",
    "\n",
    "# Classify a list of adjectives and compute class-wise proportions\n",
    "def classify_and_summarize(word_list, model, human_vec, product_vec):\n",
    "    classified = {\"person\": [], \"product\": []}\n",
    "    for word in word_list:\n",
    "        label = classify_adj_by_prototype(word, model, human_vec, product_vec)\n",
    "        if label:\n",
    "            classified[label].append(word)\n",
    "\n",
    "    total = len(classified[\"person\"]) + len(classified[\"product\"])\n",
    "    ratio = {\n",
    "        \"person\": len(classified[\"person\"]) / total if total > 0 else 0,\n",
    "        \"product\": len(classified[\"product\"]) / total if total > 0 else 0\n",
    "    }\n",
    "    return classified, ratio\n",
    "\n",
    "# File paths for adjective CSVs\n",
    "path_person_csv = \"filtered_person_adjs.csv\"\n",
    "path_product_csv = \"filtered_product_adjs.csv\"\n",
    "\n",
    "# Load adjective lists\n",
    "person_adjs = load_adjectives_from_csv(path_person_csv)\n",
    "product_adjs = load_adjectives_from_csv(path_product_csv)\n",
    "\n",
    "# Classify each list and compute ratios\n",
    "classified_person, ratio_person = classify_and_summarize(person_adjs, model, human_vec, product_vec)\n",
    "classified_product, ratio_product = classify_and_summarize(product_adjs, model, human_vec, product_vec)\n",
    "\n",
    "# Print classification results\n",
    "print(\"Results for filtered_person_adjs.csv:\")\n",
    "print(\"  → classified as person:\", len(classified_person[\"person\"]))\n",
    "print(\"  → classified as product:\", len(classified_person[\"product\"]))\n",
    "print(\"  → ratio:\", ratio_person)\n",
    "\n",
    "print(\"\\nResults for strong_product_adjs.csv:\")\n",
    "print(\"  → classified as person:\", len(classified_product[\"person\"]))\n",
    "print(\"  → classified as product:\", len(classified_product[\"product\"]))\n",
    "print(\"  → ratio:\", ratio_product)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5bbd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save classified_person to CSV\n",
    "pd.DataFrame({\n",
    "    \"adj\": classified_person[\"person\"] + classified_person[\"product\"],\n",
    "    \"classified_as\": [\"person\"] * len(classified_person[\"person\"]) + [\"product\"] * len(classified_person[\"product\"])\n",
    "}).to_csv(\"classified_person_adjs_by_vector.csv\", index=False)\n",
    "\n",
    "# Save classified_product to CSV\n",
    "pd.DataFrame({\n",
    "    \"adj\": classified_product[\"person\"] + classified_product[\"product\"],\n",
    "    \"classified_as\": [\"person\"] * len(classified_product[\"person\"]) + [\"product\"] * len(classified_product[\"product\"])\n",
    "}).to_csv(\"classified_product_adjs_by_vector.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44eb8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "\n",
    "# Function to classify and return scores\n",
    "def classify_adj_with_score(adj_list, model, human_vec, product_vec):\n",
    "    results = []\n",
    "    for word in adj_list:\n",
    "        if word not in model:\n",
    "            continue\n",
    "        v = model[word]\n",
    "        sim_person = 1 - cosine(v, human_vec)\n",
    "        sim_product = 1 - cosine(v, product_vec)\n",
    "        label = \"person\" if sim_person > sim_product else \"product\"\n",
    "        results.append({\n",
    "            \"adj\": word,\n",
    "            \"classified_as\": label,\n",
    "            \"sim_to_person\": sim_person,\n",
    "            \"sim_to_product\": sim_product\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Re-run classification with similarity scores\n",
    "df_person = classify_adj_with_score(person_adjs, model, human_vec, product_vec)\n",
    "df_product = classify_adj_with_score(product_adjs, model, human_vec, product_vec)\n",
    "\n",
    "# Save to CSV\n",
    "df_person.to_csv(\"classified_person_adjs_by_vector.csv\", index=False)\n",
    "df_product.to_csv(\"classified_product_adjs_by_vector.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a659561",
   "metadata": {},
   "source": [
    "## Embedddin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "967f8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_vec = human_vec - product_vec  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483c8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_score(word, model, direction_vec):\n",
    "    if word not in model:\n",
    "        return None\n",
    "    v = model[word]\n",
    "    # 单位投影长度（可正可负）\n",
    "    return np.dot(v, direction_vec) / np.linalg.norm(direction_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c8d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elegant', np.float32(-0.032249287)),\n",
       " ('warm', np.float32(-0.45854154)),\n",
       " ('sharp', np.float32(-0.6423682)),\n",
       " ('aggressive', np.float32(-0.7012519)),\n",
       " ('soft', np.float32(-0.9269208)),\n",
       " ('rigid', np.float32(-1.1526953)),\n",
       " ('compact', np.float32(-1.2540897)),\n",
       " ('plastic', np.float32(-1.7011349))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_scores = {adj: projection_score(adj, model, direction_vec)\n",
    "              for adj in adjectives_to_test if adj in model}\n",
    "\n",
    "\n",
    "sorted(adj_scores.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12623f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 6.2144\n",
      "P-value: 0.00000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === Step 1: load adjective lists from CSV ===\n",
    "path_person_csv = \"filtered_person_adjs.csv\"\n",
    "path_product_csv = \"filtered_product_adjs.csv\"\n",
    "\n",
    "person_adjs = pd.read_csv(path_person_csv).iloc[:, 0].dropna().unique().tolist()\n",
    "product_adjs = pd.read_csv(path_product_csv).iloc[:, 0].dropna().unique().tolist()\n",
    "\n",
    "# === Step 2: define projection scoring function ===\n",
    "def projection_score(word, model, direction_vec):\n",
    "    if word not in model:\n",
    "        return None\n",
    "    vec = model[word]\n",
    "    return np.dot(vec, direction_vec) / (np.linalg.norm(vec) * np.linalg.norm(direction_vec))\n",
    "\n",
    "# === Step 3: calculate scores ===\n",
    "person_scores = {\n",
    "    word: projection_score(word, model, direction_vec)\n",
    "    for word in person_adjs if word in model\n",
    "}\n",
    "\n",
    "product_scores = {\n",
    "    word: projection_score(word, model, direction_vec)\n",
    "    for word in product_adjs if word in model\n",
    "}\n",
    "\n",
    "# === Step 4: convert to DataFrames and sort ===\n",
    "df_person_scores = pd.DataFrame([\n",
    "    {\"adj\": word, \"projection_score\": score}\n",
    "    for word, score in person_scores.items()\n",
    "]).sort_values(\"projection_score\", ascending=False)\n",
    "\n",
    "df_product_scores = pd.DataFrame([\n",
    "    {\"adj\": word, \"projection_score\": score}\n",
    "    for word, score in product_scores.items()\n",
    "]).sort_values(\"projection_score\", ascending=False)\n",
    "\n",
    "# === Step 5: save to CSV ===\n",
    "df_person_scores.to_csv(\"projection_scores_person.csv\", index=False)\n",
    "df_product_scores.to_csv(\"projection_scores_product.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9fc3daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 6.2144\n",
      "P-value: 0.00000\n",
      "Mean (person list): -0.0634\n",
      "Mean (product list): -0.1007\n",
      "→ Adjectives in the person list have a higher average projection score.\n"
     ]
    }
   ],
   "source": [
    "# === Step 6: t-test comparison ===\n",
    "person_vals = list(person_scores.values())\n",
    "product_vals = list(product_scores.values())\n",
    "\n",
    "t_stat, p_value = ttest_ind(person_vals, product_vals, equal_var=False)\n",
    "\n",
    "mean_person = np.mean(person_vals)\n",
    "mean_product = np.mean(product_vals)\n",
    "\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.5f}\")\n",
    "print(f\"Mean (person list): {mean_person:.4f}\")\n",
    "print(f\"Mean (product list): {mean_product:.4f}\")\n",
    "\n",
    "if mean_person > mean_product:\n",
    "    print(\"→ Adjectives in the person list have a higher average projection score.\")\n",
    "elif mean_person < mean_product:\n",
    "    print(\"→ Adjectives in the product list have a higher average projection score.\")\n",
    "else:\n",
    "    print(\"→ Both lists have the same mean projection score.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_nouns = [\n",
    "    # ========== 基础人称 ==========\n",
    "    \"person\", \"people\", \"human\", \"humans\", \"mankind\", \"humankind\",\n",
    "    \"individual\", \"individuals\", \"being\", \"beings\",\n",
    "    \"someone\", \"somebody\", \"anyone\", \"anybody\", \"everyone\", \"everybody\",\n",
    "    \"one\", \"ones\", \"other\", \"others\", \"another\",\n",
    "    \"self\", \"selves\", \"ego\", \"egos\",\n",
    "    \"soul\", \"souls\", \"spirit\", \"spirits\",\n",
    "    \"mortal\", \"mortals\",\n",
    "    \n",
    "    # ========== 性别/年龄 ==========\n",
    "    # 男性\n",
    "    \"man\", \"men\", \"male\", \"males\", \"gentleman\", \"gentlemen\",\n",
    "    \"guy\", \"guys\", \"dude\", \"dudes\", \"fellow\", \"fellows\",\n",
    "    \"lad\", \"lads\", \"chap\", \"chaps\", \"bloke\", \"blokes\",\n",
    "    \n",
    "    # 女性\n",
    "    \"woman\", \"women\", \"female\", \"females\", \"lady\", \"ladies\",\n",
    "    \"gal\", \"gals\", \"lass\", \"lasses\", \"dame\", \"dames\",\n",
    "    \"maiden\", \"maidens\", \"mistress\", \"mistresses\",\n",
    "    \n",
    "    # 儿童/青少年\n",
    "    \"child\", \"children\", \"kid\", \"kids\", \"youngster\", \"youngsters\",\n",
    "    \"baby\", \"babies\", \"infant\", \"infants\", \"newborn\", \"newborns\",\n",
    "    \"toddler\", \"toddlers\", \"tot\", \"tots\",\n",
    "    \"boy\", \"boys\", \"girl\", \"girls\",\n",
    "    \"schoolboy\", \"schoolboys\", \"schoolgirl\", \"schoolgirls\",\n",
    "    \"teenager\", \"teenagers\", \"teen\", \"teens\",\n",
    "    \"adolescent\", \"adolescents\", \"youth\", \"youths\",\n",
    "    \"minor\", \"minors\", \"juvenile\", \"juveniles\",\n",
    "    \n",
    "    # 成年/老年\n",
    "    \"adult\", \"adults\", \"grownup\", \"grownups\",\n",
    "    \"elder\", \"elders\", \"senior\", \"seniors\",\n",
    "    \"oldster\", \"oldsters\", \"retiree\", \"retirees\",\n",
    "    \"pensioner\", \"pensioners\",\n",
    "    \n",
    "    # 其他年龄\n",
    "    \"junior\", \"juniors\", \"youngster\", \"youngsters\",\n",
    "    \n",
    "    # 通用\n",
    "    \"folk\", \"folks\", \"people\",\n",
    "    \n",
    "    # ========== 家庭关系 ==========\n",
    "    # 父母\n",
    "    \"parent\", \"parents\", \"father\", \"fathers\", \"mother\", \"mothers\",\n",
    "    \"dad\", \"dads\", \"daddy\", \"mom\", \"moms\", \"mommy\", \"mama\", \"papa\",\n",
    "    \"stepfather\", \"stepfathers\", \"stepmother\", \"stepmothers\",\n",
    "    \"stepparent\", \"stepparents\",\n",
    "    \"forefather\", \"forefathers\", \"foremother\", \"foremothers\",\n",
    "    \n",
    "    # 子女\n",
    "    \"son\", \"sons\", \"daughter\", \"daughters\",\n",
    "    \"child\", \"children\", \"offspring\",\n",
    "    \"stepson\", \"stepsons\", \"stepdaughter\", \"stepdaughters\",\n",
    "    \"stepchild\", \"stepchildren\",\n",
    "    \n",
    "    # 兄弟姐妹\n",
    "    \"brother\", \"brothers\", \"sister\", \"sisters\", \"sibling\", \"siblings\",\n",
    "    \"stepbrother\", \"stepbrothers\", \"stepsister\", \"stepsisters\",\n",
    "    \"halfbrother\", \"halfbrothers\", \"halfsister\", \"halfsisters\",\n",
    "    \"twin\", \"twins\", \"triplet\", \"triplets\",\n",
    "    \n",
    "    # 祖辈\n",
    "    \"grandfather\", \"grandfathers\", \"grandmother\", \"grandmothers\",\n",
    "    \"grandpa\", \"grandpas\", \"grandma\", \"grandmas\", \"granny\", \"grannies\",\n",
    "    \"grandparent\", \"grandparents\",\n",
    "    \"greatgrandfather\", \"greatgrandmothers\",\n",
    "    \n",
    "    # 孙辈\n",
    "    \"grandson\", \"grandsons\", \"granddaughter\", \"granddaughters\",\n",
    "    \"grandchild\", \"grandchildren\",\n",
    "    \"greatgrandson\", \"greatgranddaughter\",\n",
    "    \n",
    "    # 叔伯姑姨\n",
    "    \"uncle\", \"uncles\", \"aunt\", \"aunts\",\n",
    "    \"nephew\", \"nephews\", \"niece\", \"nieces\",\n",
    "    \"cousin\", \"cousins\",\n",
    "    \"greatuncle\", \"greataunt\",\n",
    "    \n",
    "    # 配偶/伴侣\n",
    "    \"husband\", \"husbands\", \"wife\", \"wives\", \"spouse\", \"spouses\",\n",
    "    \"partner\", \"partners\", \"companion\", \"companions\",\n",
    "    \"boyfriend\", \"boyfriends\", \"girlfriend\", \"girlfriends\",\n",
    "    \"fiance\", \"fiancee\", \"betrothed\",\n",
    "    \"lover\", \"lovers\", \"sweetheart\", \"sweethearts\",\n",
    "    \"mate\", \"mates\", \"soulmate\", \"soulmates\",\n",
    "    \"bride\", \"brides\", \"groom\", \"grooms\", \"bridegroom\", \"bridegrooms\",\n",
    "    \"newlywed\", \"newlyweds\",\n",
    "    \n",
    "    # 其他家庭\n",
    "    \"ancestor\", \"ancestors\", \"descendant\", \"descendants\",\n",
    "    \"relative\", \"relatives\", \"relation\", \"relations\",\n",
    "    \"kin\", \"kinfolk\", \"kinsfolk\", \"kinsman\", \"kinswoman\",\n",
    "    \"family\", \"families\",\n",
    "    \"godfather\", \"godfathers\", \"godmother\", \"godmothers\",\n",
    "    \"godparent\", \"godparents\", \"godson\", \"godsons\",\n",
    "    \"goddaughter\", \"goddaughters\", \"godchild\", \"godchildren\",\n",
    "    \"inlaw\", \"inlaws\",\n",
    "    \n",
    "    # ========== 社会关系 ==========\n",
    "    # 朋友\n",
    "    \"friend\", \"friends\", \"buddy\", \"buddies\", \"pal\", \"pals\",\n",
    "    \"mate\", \"mates\", \"chum\", \"chums\", \"crony\", \"cronies\",\n",
    "    \"companion\", \"companions\", \"comrade\", \"comrades\",\n",
    "    \"confidant\", \"confidante\", \"confidants\",\n",
    "    \"acquaintance\", \"acquaintances\",\n",
    "    \"peer\", \"peers\", \"equal\", \"equals\",\n",
    "    \n",
    "    # 室友/邻居\n",
    "    \"roommate\", \"roommates\", \"housemate\", \"housemates\",\n",
    "    \"flatmate\", \"flatmates\", \"suitemate\", \"suitemates\",\n",
    "    \"neighbor\", \"neighbors\", \"neighbour\", \"neighbours\",\n",
    "    \n",
    "    # 陌生人\n",
    "    \"stranger\", \"strangers\", \"outsider\", \"outsiders\",\n",
    "    \"newcomer\", \"newcomers\",\n",
    "    \n",
    "    # 敌友关系\n",
    "    \"ally\", \"allies\", \"friend\", \"friends\",\n",
    "    \"enemy\", \"enemies\", \"foe\", \"foes\",\n",
    "    \"rival\", \"rivals\", \"opponent\", \"opponents\",\n",
    "    \"adversary\", \"adversaries\", \"antagonist\", \"antagonists\",\n",
    "    \"nemesis\", \"nemeses\",\n",
    "    \n",
    "    # 英雄/反派\n",
    "    \"hero\", \"heroes\", \"heroine\", \"heroines\",\n",
    "    \"villain\", \"villains\", \"evildoer\", \"evildoers\",\n",
    "    \"savior\", \"saviors\", \"rescuer\", \"rescuers\",\n",
    "    \n",
    "    # ========== 社会身份/国籍 ==========\n",
    "    \"citizen\", \"citizens\", \"national\", \"nationals\",\n",
    "    \"resident\", \"residents\", \"inhabitant\", \"inhabitants\",\n",
    "    \"dweller\", \"dwellers\", \"occupant\", \"occupants\",\n",
    "    \"native\", \"natives\", \"local\", \"locals\",\n",
    "    \"foreigner\", \"foreigners\", \"alien\", \"aliens\",\n",
    "    \"immigrant\", \"immigrants\", \"emigrant\", \"emigrants\",\n",
    "    \"migrant\", \"migrants\", \"refugee\", \"refugees\",\n",
    "    \"exile\", \"exiles\", \"expatriate\", \"expatriates\",\n",
    "    \"settler\", \"settlers\", \"colonist\", \"colonists\",\n",
    "    \"nomad\", \"nomads\", \"wanderer\", \"wanderers\",\n",
    "    \n",
    "    # ========== 访客/旅行者 ==========\n",
    "    \"guest\", \"guests\", \"visitor\", \"visitors\",\n",
    "    \"tourist\", \"tourists\", \"traveler\", \"travelers\",\n",
    "    \"voyager\", \"voyagers\", \"explorer\", \"explorers\",\n",
    "    \"passenger\", \"passengers\", \"commuter\", \"commuters\",\n",
    "    \"pedestrian\", \"pedestrians\", \"walker\", \"walkers\",\n",
    "    \"motorist\", \"motorists\", \"driver\", \"drivers\",\n",
    "    \"rider\", \"riders\", \"cyclist\", \"cyclists\",\n",
    "    \"hitchhiker\", \"hitchhikers\",\n",
    "    \n",
    "    # ========== 群体成员 ==========\n",
    "    \"member\", \"members\", \"participant\", \"participants\",\n",
    "    \"attendee\", \"attendees\", \"goer\", \"goers\",\n",
    "    \"volunteer\", \"volunteers\",\n",
    "    \"supporter\", \"supporters\", \"backer\", \"backers\",\n",
    "    \"follower\", \"followers\", \"disciple\", \"disciples\",\n",
    "    \"adherent\", \"adherents\", \"devotee\", \"devotees\",\n",
    "    \"fan\", \"fans\", \"admirer\", \"admirers\",\n",
    "    \"enthusiast\", \"enthusiasts\", \"aficionado\", \"aficionados\",\n",
    "    \"buff\", \"buffs\", \"fanatic\", \"fanatics\",\n",
    "    \n",
    "    # ========== 抗议/活动者 ==========\n",
    "    \"activist\", \"activists\", \"campaigner\", \"campaigners\",\n",
    "    \"protester\", \"protesters\", \"demonstrator\", \"demonstrators\",\n",
    "    \"marcher\", \"marchers\", \"striker\", \"strikers\",\n",
    "    \"rebel\", \"rebels\", \"revolutionary\", \"revolutionaries\",\n",
    "    \"dissident\", \"dissidents\", \"insurgent\", \"insurgents\",\n",
    "    \n",
    "    # ========== 候选/代表 ==========\n",
    "    \"candidate\", \"candidates\", \"applicant\", \"applicants\",\n",
    "    \"nominee\", \"nominees\", \"contender\", \"contenders\",\n",
    "    \"representative\", \"representatives\", \"delegate\", \"delegates\",\n",
    "    \"deputy\", \"deputies\", \"envoy\", \"envoys\",\n",
    "    \"ambassador\", \"ambassadors\", \"emissary\", \"emissaries\",\n",
    "    \"spokesman\", \"spokesmen\", \"spokesperson\", \"spokespersons\",\n",
    "    \"advocate\", \"advocates\", \"champion\", \"champions\",\n",
    "    \n",
    "    # ========== 主办/组织者 ==========\n",
    "    \"host\", \"hosts\", \"hostess\", \"hostesses\",\n",
    "    \"organizer\", \"organizers\", \"coordinator\", \"coordinators\",\n",
    "    \"planner\", \"planners\", \"arranger\", \"arrangers\",\n",
    "    \n",
    "    # ========== 受害/涉事者 ==========\n",
    "    \"victim\", \"victims\", \"casualty\", \"casualties\",\n",
    "    \"survivor\", \"survivors\", \"sufferer\", \"sufferers\",\n",
    "    \"martyr\", \"martyrs\",\n",
    "    \"witness\", \"witnesses\", \"eyewitness\", \"eyewitnesses\",\n",
    "    \"bystander\", \"bystanders\", \"onlooker\", \"onlookers\",\n",
    "    \"spectator\", \"spectators\",\n",
    "    \n",
    "    # ========== 犯罪/法律 ==========\n",
    "    \"suspect\", \"suspects\", \"accused\",\n",
    "    \"criminal\", \"criminals\", \"offender\", \"offenders\",\n",
    "    \"culprit\", \"culprits\", \"perpetrator\", \"perpetrators\",\n",
    "    \"wrongdoer\", \"wrongdoers\", \"lawbreaker\", \"lawbreakers\",\n",
    "    \"felon\", \"felons\", \"convict\", \"convicts\",\n",
    "    \"prisoner\", \"prisoners\", \"inmate\", \"inmates\",\n",
    "    \"captive\", \"captives\", \"detainee\", \"detainees\",\n",
    "    \"hostage\", \"hostages\",\n",
    "    \"fugitive\", \"fugitives\", \"runaway\", \"runaways\",\n",
    "    \"outlaw\", \"outlaws\", \"bandit\", \"bandits\",\n",
    "    \"thief\", \"thieves\", \"robber\", \"robbers\",\n",
    "    \"burglar\", \"burglars\", \"mugger\", \"muggers\",\n",
    "    \"kidnapper\", \"kidnappers\", \"abductor\", \"abductors\",\n",
    "    \"smuggler\", \"smugglers\", \"dealer\", \"dealers\",\n",
    "    \"traitor\", \"traitors\", \"spy\", \"spies\",\n",
    "    \n",
    "    # ========== 沟通/互动角色 ==========\n",
    "    \"speaker\", \"speakers\", \"orator\", \"orators\",\n",
    "    \"listener\", \"listeners\", \"hearer\", \"hearers\",\n",
    "    \"talker\", \"talkers\", \"conversationalist\", \"conversationalists\",\n",
    "    \"gossip\", \"gossips\", \"chatterer\", \"chatterers\",\n",
    "    \"storyteller\", \"storytellers\", \"narrator\", \"narrators\",\n",
    "    \n",
    "    # ========== 读写/观看 ==========\n",
    "    \"reader\", \"readers\", \"writer\", \"writers\",\n",
    "    \"viewer\", \"viewers\", \"watcher\", \"watchers\",\n",
    "    \"observer\", \"observers\", \"looker\", \"lookers\",\n",
    "    \"audience\", \"spectator\", \"spectators\",\n",
    "    \"commentator\", \"commentators\",\n",
    "    \"critic\", \"critics\", \"reviewer\", \"reviewers\",\n",
    "    \n",
    "    # ========== 信息/消息 ==========\n",
    "    \"messenger\", \"messengers\", \"courier\", \"couriers\",\n",
    "    \"informant\", \"informants\", \"informer\", \"informers\",\n",
    "    \"source\", \"sources\", \"tipster\", \"tipsters\",\n",
    "    \"contact\", \"contacts\",\n",
    "    \"whistleblower\", \"whistleblowers\",\n",
    "    \n",
    "    # ========== 消费/交易 ==========\n",
    "    \"customer\", \"customers\", \"client\", \"clients\",\n",
    "    \"consumer\", \"consumers\", \"patron\", \"patrons\",\n",
    "    \"buyer\", \"buyers\", \"purchaser\", \"purchasers\",\n",
    "    \"seller\", \"sellers\", \"vendor\", \"vendors\",\n",
    "    \"merchant\", \"merchants\", \"trader\", \"traders\",\n",
    "    \"dealer\", \"dealers\", \"retailer\", \"retailers\",\n",
    "    \"shopper\", \"shoppers\", \"browser\", \"browsers\",\n",
    "    \n",
    "    # ========== 使用/拥有 ==========\n",
    "    \"user\", \"users\", \"owner\", \"owners\",\n",
    "    \"holder\", \"holders\", \"bearer\", \"bearers\",\n",
    "    \"possessor\", \"possessors\", \"keeper\", \"keepers\",\n",
    "    \"tenant\", \"tenants\", \"occupant\", \"occupants\",\n",
    "    \"landlord\", \"landlords\", \"landlady\", \"landladies\",\n",
    "    \n",
    "    # ========== 特殊身份/状态 ==========\n",
    "    # 婚姻状态\n",
    "    \"bachelor\", \"bachelors\", \"bachelorette\", \"bachelorettes\",\n",
    "    \"spinster\", \"spinsters\",\n",
    "    \"divorcee\", \"divorcees\",\n",
    "    \"widow\", \"widows\", \"widower\", \"widowers\",\n",
    "    \n",
    "    # 孤儿/弃儿\n",
    "    \"orphan\", \"orphans\", \"foundling\", \"foundlings\",\n",
    "    \"waif\", \"waifs\", \"stray\", \"strays\",\n",
    "    \n",
    "    # 退休/老兵\n",
    "    \"veteran\", \"veterans\", \"retiree\", \"retirees\",\n",
    "    \"pensioner\", \"pensioners\",\n",
    "    \n",
    "    # 富人/穷人\n",
    "    \"millionaire\", \"millionaires\", \"billionaire\", \"billionaires\",\n",
    "    \"tycoon\", \"tycoons\", \"magnate\", \"magnates\",\n",
    "    \"pauper\", \"paupers\", \"beggar\", \"beggars\",\n",
    "    \"vagrant\", \"vagrants\", \"tramp\", \"tramps\",\n",
    "    \"homeless\", \"panhandler\", \"panhandlers\",\n",
    "    \n",
    "    # 名人/明星\n",
    "    \"celebrity\", \"celebrities\", \"star\", \"stars\",\n",
    "    \"icon\", \"icons\", \"idol\", \"idols\",\n",
    "    \"superstar\", \"superstars\", \"legend\", \"legends\",\n",
    "    \"personality\", \"personalities\", \"figure\", \"figures\",\n",
    "    \"influencer\", \"influencers\",\n",
    "    \n",
    "    # 天才/人才\n",
    "    \"genius\", \"geniuses\", \"prodigy\", \"prodigies\",\n",
    "    \"talent\", \"talents\", \"virtuoso\", \"virtuosos\",\n",
    "    \"mastermind\", \"masterminds\", \"whiz\", \"wizard\", \"wizards\",\n",
    "    \n",
    "    # 专家/新手\n",
    "    \"expert\", \"experts\", \"specialist\", \"specialists\",\n",
    "    \"authority\", \"authorities\", \"connoisseur\", \"connoisseurs\",\n",
    "    \"professional\", \"professionals\", \"pro\", \"pros\",\n",
    "    \"novice\", \"novices\", \"beginner\", \"beginners\",\n",
    "    \"amateur\", \"amateurs\", \"rookie\", \"rookies\",\n",
    "    \"learner\", \"learners\", \"trainee\", \"trainees\",\n",
    "    \n",
    "    # 主人/奴隶\n",
    "    \"master\", \"masters\", \"mistress\", \"mistresses\",\n",
    "    \"lord\", \"lords\", \"sovereign\", \"sovereigns\",\n",
    "    \"apprentice\", \"apprentices\", \"protege\", \"proteges\",\n",
    "    \"servant\", \"servants\", \"slave\", \"slaves\",\n",
    "    \"serf\", \"serfs\", \"vassal\", \"vassals\",\n",
    "    \n",
    "    # ========== 照顾/监护 ==========\n",
    "    \"guardian\", \"guardians\", \"custodian\", \"custodians\",\n",
    "    \"caretaker\", \"caretakers\", \"keeper\", \"keepers\",\n",
    "    \"babysitter\", \"babysitters\", \"sitter\", \"sitters\",\n",
    "    \"nanny\", \"nannies\", \"governess\", \"governesses\",\n",
    "    \"minder\", \"minders\",\n",
    "    \"guide\", \"guides\", \"escort\", \"escorts\",\n",
    "    \"chaperone\", \"chaperones\", \"bodyguard\", \"bodyguards\",\n",
    "    \"protector\", \"protectors\", \"defender\", \"defenders\",\n",
    "    \n",
    "    # ========== 接受者/受益者 ==========\n",
    "    \"recipient\", \"recipients\", \"receiver\", \"receivers\",\n",
    "    \"beneficiary\", \"beneficiaries\", \"payee\", \"payees\",\n",
    "    \"heir\", \"heirs\", \"heiress\", \"heiresses\",\n",
    "    \"inheritor\", \"inheritors\", \"legatee\", \"legatees\",\n",
    "    \"successor\", \"successors\",\n",
    "    \"patient\", \"patients\",\n",
    "    \n",
    "    # ========== 集体名词 ==========\n",
    "    \"team\", \"teams\", \"group\", \"groups\",\n",
    "    \"crew\", \"crews\", \"gang\", \"gangs\",\n",
    "    \"band\", \"bands\", \"squad\", \"squads\",\n",
    "    \"troop\", \"troops\", \"unit\", \"units\",\n",
    "    \"party\", \"parties\", \"faction\", \"factions\",\n",
    "    \"crowd\", \"crowds\", \"mob\", \"mobs\",\n",
    "    \"throng\", \"throngs\", \"horde\", \"hordes\",\n",
    "    \"swarm\", \"swarms\", \"mass\", \"masses\",\n",
    "    \"assembly\", \"assemblies\", \"gathering\", \"gatherings\",\n",
    "    \"congregation\", \"congregations\", \"audience\", \"audiences\",\n",
    "    \"community\", \"communities\", \"society\", \"societies\",\n",
    "    \"population\", \"populations\", \"public\", \"populace\",\n",
    "    \"citizenry\", \"constituency\", \"electorate\",\n",
    "    \"generation\", \"generations\", \"cohort\", \"cohorts\",\n",
    "    \"class\", \"classes\", \"batch\", \"batches\",\n",
    "    \"set\", \"sets\", \"circle\", \"circles\",\n",
    "    \"clan\", \"clans\", \"tribe\", \"tribes\",\n",
    "    \"dynasty\", \"dynasties\", \"lineage\", \"lineages\",\n",
    "    \n",
    "    # ========== 其他 ==========\n",
    "    \"character\", \"characters\", \"personality\", \"personalities\",\n",
    "    \"individual\", \"individuals\", \"entity\", \"entities\",\n",
    "    \"creature\", \"creatures\", \"organism\", \"organisms\",\n",
    "    \"player\", \"players\", \"participant\", \"participants\",\n",
    "    \"actor\", \"actors\", \"agent\", \"agents\",\n",
    "    \"doer\", \"doers\", \"maker\", \"makers\",\n",
    "    \"creator\", \"creators\", \"founder\", \"founders\",\n",
    "    \"inventor\", \"inventors\", \"pioneer\", \"pioneers\",\n",
    "    \"leader\", \"leaders\", \"follower\", \"followers\",\n",
    "    \"chief\", \"chiefs\", \"head\", \"heads\",\n",
    "    \"boss\", \"bosses\", \"superior\", \"superiors\",\n",
    "    \"subordinate\", \"subordinates\", \"underling\", \"underlings\",\n",
    "    \"helper\", \"helpers\", \"assistant\", \"assistants\",\n",
    "    \"aide\", \"aides\", \"attendant\", \"attendants\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 500 High-Frequency English Names (250 Male, 250 Female)\n",
    "# Sorted roughly by frequency/popularity over the last century + modern trends.\n",
    "\n",
    "common_names = [\n",
    "        \"James\", \"John\", \"Robert\", \"Michael\", \"William\", \"David\", \"Richard\", \"Joseph\", \"Thomas\", \"Charles\",\n",
    "        \"Christopher\", \"Daniel\", \"Matthew\", \"Anthony\", \"Donald\", \"Mark\", \"Paul\", \"Steven\", \"Andrew\", \"Kenneth\",\n",
    "        \"Joshua\", \"George\", \"Kevin\", \"Brian\", \"Edward\", \"Ronald\", \"Timothy\", \"Jason\", \"Jeffrey\", \"Ryan\",\n",
    "        \"Jacob\", \"Gary\", \"Nicholas\", \"Eric\", \"Stephen\", \"Jonathan\", \"Larry\", \"Justin\", \"Scott\", \"Brandon\",\n",
    "        \"Frank\", \"Benjamin\", \"Gregory\", \"Samuel\", \"Raymond\", \"Patrick\", \"Alexander\", \"Jack\", \"Dennis\", \"Jerry\",\n",
    "        \"Tyler\", \"Aaron\", \"Henry\", \"Jose\", \"Douglas\", \"Peter\", \"Adam\", \"Nathan\", \"Zachary\", \"Walter\",\n",
    "        \"Kyle\", \"Harold\", \"Carl\", \"Jeremy\", \"Keith\", \"Roger\", \"Gerald\", \"Ethan\", \"Arthur\", \"Terry\",\n",
    "        \"Christian\", \"Sean\", \"Lawrence\", \"Austin\", \"Joe\", \"Noah\", \"Jesse\", \"Albert\", \"Billy\", \"Bruce\",\n",
    "        \"Willie\", \"Jordan\", \"Dylan\", \"Bryan\", \"Eugene\", \"Ralph\", \"Roy\", \"Alan\", \"Wayne\", \"Harry\",\n",
    "        \"Louis\", \"Juan\", \"Gabriel\", \"Randy\", \"Philip\", \"Vincent\", \"Russell\", \"Bobby\", \"Johnny\", \"Logan\",\n",
    "        \"Howard\", \"Liam\", \"Mason\", \"Elijah\", \"Oliver\", \"Lucas\", \"Caleb\", \"Jackson\", \"Hunter\", \"Connor\",\n",
    "        \"Aiden\", \"Evan\", \"Isaac\", \"Luke\", \"Cameron\", \"Owen\", \"Landon\", \"Julian\", \"Brayden\", \"Gavin\",\n",
    "        \"Levi\", \"Isaiah\", \"David\", \"Sebastian\", \"Jack\", \"Wyatt\", \"Jayden\", \"Eli\", \"Aaron\", \"Charles\",\n",
    "        \"Henry\", \"Lincoln\", \"Hudson\", \"Theodore\", \"Mateo\", \"Leo\", \"Jaxon\", \"Miles\", \"Nolan\", \"Asher\",\n",
    "        \"Ezra\", \"Elias\", \"Colton\", \"Maverick\", \"Bryson\", \"Axel\", \"Easton\", \"Santiago\", \"Cooper\", \"Jeremiah\",\n",
    "        \"Angel\", \"Roman\", \"Ian\", \"Carson\", \"Robert\", \"Jameson\", \"Parker\", \"Dominic\", \"Kayden\", \"Ayden\",\n",
    "        \"Jason\", \"Xavier\", \"Greyson\", \"Jace\", \"Austin\", \"Adam\", \"Wesley\", \"Kai\", \"Chase\", \"Cole\",\n",
    "        \"Carlos\", \"Jesus\", \"Adrian\", \"Antonio\", \"Miguel\", \"Diego\", \"Alejandro\", \"Victor\", \"Manuel\", \"Francisco\",\n",
    "        \"Mario\", \"Luis\", \"Jorge\", \"Eduardo\", \"Roberto\", \"Ricardo\", \"Fernando\", \"Hector\", \"Oscar\", \"Ramon\",\n",
    "        \"Travis\", \"Clarence\", \"Lester\", \"Edwin\", \"Fred\", \"Herbert\", \"Norman\", \"Marvin\", \"Lee\", \"Melvin\",\n",
    "        \"Alfred\", \"Francis\", \"Dale\", \"Earl\", \"Stanley\", \"Leonard\", \"Rodney\", \"Curtis\", \"Glen\", \"Jeff\",\n",
    "        \"Chad\", \"Shawn\", \"Eddie\", \"Ricky\", \"Troy\", \"Randall\", \"Barry\", \"Bernard\", \"Leroy\", \"Marcus\",\n",
    "        \"Micheal\", \"Theodore\", \"Clifford\", \"Jay\", \"Jim\", \"Tom\", \"Calvin\", \"Alex\", \"Jon\", \"Ronnie\",\n",
    "        \"Bill\", \"Lloyd\", \"Tommy\", \"Leon\", \"Derek\", \"Wes\", \"Dan\", \"Sam\", \"Ben\", \"Will\"\n",
    "\n",
    "        \"Mary\", \"Patricia\", \"Jennifer\", \"Linda\", \"Elizabeth\", \"Barbara\", \"Susan\", \"Jessica\", \"Sarah\", \"Karen\",\n",
    "        \"Nancy\", \"Lisa\", \"Margaret\", \"Betty\", \"Sandra\", \"Ashley\", \"Dorothy\", \"Kimberly\", \"Emily\", \"Donna\",\n",
    "        \"Michelle\", \"Carol\", \"Amanda\", \"Melissa\", \"Deborah\", \"Stephanie\", \"Rebecca\", \"Laura\", \"Sharon\", \"Cynthia\",\n",
    "        \"Kathleen\", \"Amy\", \"Shirley\", \"Angela\", \"Helen\", \"Anna\", \"Brenda\", \"Pamela\", \"Nicole\", \"Emma\",\n",
    "        \"Samantha\", \"Katherine\", \"Christine\", \"Debra\", \"Rachel\", \"Catherine\", \"Carolyn\", \"Janet\", \"Ruth\", \"Maria\",\n",
    "        \"Heather\", \"Diane\", \"Virginia\", \"Julie\", \"Joyce\", \"Victoria\", \"Olivia\", \"Kelly\", \"Christina\", \"Lauren\",\n",
    "        \"Joan\", \"Evelyn\", \"Judith\", \"Megan\", \"Cheryl\", \"Andrea\", \"Hannah\", \"Martha\", \"Jacqueline\", \"Frances\",\n",
    "        \"Gloria\", \"Ann\", \"Teresa\", \"Kathryn\", \"Sara\", \"Janice\", \"Jean\", \"Alice\", \"Madison\", \"Doris\",\n",
    "        \"Abigail\", \"Julia\", \"Grace\", \"Judy\", \"Sophia\", \"Amber\", \"Marilyn\", \"Danielle\", \"Beverly\", \"Isabella\",\n",
    "        \"Theresa\", \"Diana\", \"Natalie\", \"Brittany\", \"Charlotte\", \"Marie\", \"Kayla\", \"Alexis\", \"Lori\", \"Ava\",\n",
    "        \"Mia\", \"Zoe\", \"Lily\", \"Layla\", \"Chloe\", \"Amelia\", \"Harper\", \"Evelyn\", \"Avery\", \"Sofia\",\n",
    "        \"Ella\", \"Scarlett\", \"Riley\", \"Aria\", \"Zoey\", \"Penelope\", \"Lillian\", \"Addison\", \"Aubrey\", \"Ellie\",\n",
    "        \"Stella\", \"Natalie\", \"Leah\", \"Willow\", \"Lucy\", \"Paisley\", \"Savannah\", \"Brooklyn\", \"Hazel\", \"Nora\",\n",
    "        \"Mila\", \"Claire\", \"Skylar\", \"Violet\", \"Aurora\", \"Bella\", \"Nova\", \"Emilia\", \"Maya\", \"Everly\",\n",
    "        \"Audrey\", \"Eleanor\", \"Ivy\", \"Kinsley\", \"Valentina\", \"Allison\", \"Gabriella\", \"Madelyn\", \"Cora\", \"Ruby\",\n",
    "        \"Eva\", \"Serenity\", \"Autumn\", \"Adeline\", \"Hailey\", \"Gianna\", \"Isla\", \"Elena\", \"Quinn\", \"Nevaeh\",\n",
    "        \"Piper\", \"Alice\", \"Lydia\", \"Peyton\", \"Brielle\", \"Jade\", \"Sophie\", \"Rylee\", \"Clara\", \"Hadley\",\n",
    "        \"Rose\", \"Julia\", \"Eliana\", \"Kylie\", \"Taylor\", \"Alexandra\", \"Jasmine\", \"Sydney\", \"Morgan\", \"Katherine\",\n",
    "        \"Savannah\", \"Alyssa\", \"Trinity\", \"Esther\", \"Molly\", \"Valerie\", \"Norah\", \"Eden\", \"Anastasia\", \"Kaylee\",\n",
    "        \"Juliana\", \"Cecilia\", \"Mary\", \"Maggie\", \"Hope\", \"Eliza\", \"Laila\", \"Elise\", \"Harmony\", \"Remi\",\n",
    "        \"Teagan\", \"Alexis\", \"London\", \"Lyla\", \"Adalyn\", \"Jocelyn\", \"Desiree\", \"Vivian\", \"Brynlee\", \"Raelynn\",\n",
    "        \"Jordyn\", \"Mckenna\", \"Ariel\", \"Delilah\", \"Mya\", \"Genia\", \"Trinity\", \"Vanessa\", \"Gracie\", \"Sienna\",\n",
    "        \"Gia\", \"Tatum\", \"Angelina\", \"Rachel\", \"Leilani\", \"Margot\", \"Daphne\", \"Saylor\", \"Alina\", \"Lola\",\n",
    "        \"Astrid\", \"Kenzie\", \"Sloane\", \"June\", \"Oakley\", \"Harlow\", \"Malia\", \"Phoenix\", \"Tessa\", \"Felicity\",\n",
    "    ]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
